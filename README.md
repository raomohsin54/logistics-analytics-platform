 
ğŸ“¦ Logistics Analytics Platform â€“ End-to-End Azure Data Engineering Project
This project demonstrates a modern data engineering workflow using the Medallion Architecture (Bronze â†’ Silver â†’ Gold) to deliver operational logistics insights. It's designed for enterprise-scale logistics or transport companies to monitor shipment performance, delays, and fleet/vendor KPIs using:

ğŸš› Azure Data Factory
ğŸš€ Azure Databricks + PySpark
ğŸ“ Delta Lake + Parquet
ğŸ“Š Power BI for Visualization

ğŸ§± Architecture

![Architecture Diagram](https://github.com/user-attachments/assets/6610ad97-d196-454e-95de-926f9b7d493e)


ğŸ“ Folder Structure
bash
Copy
Edit
logistics-analytics-platform/
â”‚
â”œâ”€â”€ data/                    # Dummy CSVs (drivers, vendors, routes, shipments)
â”œâ”€â”€ notebooks/               # Databricks Notebooks for each layer
â”œâ”€â”€ adf_pipelines/           # ADF JSON definitions
â”œâ”€â”€ powerbi/                 # Power BI screenshots or .pbix
â”œâ”€â”€ architecture/            # Architecture diagram
â”œâ”€â”€ README.md                # This file
â””â”€â”€ .gitignore

ğŸ“Š Power BI Dashboard Features
KPI Cards: Total Shipments, Avg Delay, On-Time %

Vendor performance bar charts

Monthly delivery trend lines

Route-level delay matrix

Map visualization (simulated)

Filters: Vendor, Route Type, Origin, Destination


ğŸ“Œ Pipeline Stages
ğŸ”¹ Bronze Layer (Raw Ingestion)
Files: drivers.csv, vendors.csv, routes.csv, shipments.csv

Copied via ADF into the bronze/ container

ğŸ”¸ Silver Layer (Cleansed)
Standardized field names

Converted timestamps and distances

Saved as partitioned Parquet files

ğŸŸ¡ Gold Layer (Aggregated)
Shipment KPIs by vendor, route, month

Calculated delay time and on-time %

Output stored in gold/ container


ğŸ§  Skills Demonstrated
Metadata-driven ADF pipelines (parameterized & looped)

Databricks transformation logic with PySpark

Partitioned & incremental data processing

Delta Lake best practices (Parquet format)

End-to-end orchestration in cloud

Business-first Power BI dashboard design


ğŸ“¤ How to Reproduce
Clone this repo

Upload /data/ files to Azure Data Lake Gen2

Import ADF pipelines from /adf_pipelines/

Run notebooks in /notebooks/ inside Databricks

Load Power BI from /powerbi/ and connect to Gold layer


ğŸ“© Contact
ğŸ“§ rao.mohsin.54@gmail.com
ğŸŒ LinkedIn: https://www.linkedin.com/in/mohsin-mukhtiar/
âœï¸ Medium

â­ Star this repo if you found it useful!
